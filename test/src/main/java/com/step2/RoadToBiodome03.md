# 나의 코드 계산 횟수 예측하기

계산 속도에 있어 컴퓨터와 인간 중 누가 더 빠를까를 생각해 보면, 대부분은 비교할 필요도 없이 컴퓨터가 훨씬 빠를 것이라고 말할 것이다. 실제로도 인간이 1시간이 걸릴 계산을 컴퓨터는 순식간에 끝내는 경우가 많다.

그러면 컴퓨터의 계산에는 한계가 없을까?

안타깝게도 그렇지 않다. 아무리 빠른 컴퓨터라도 연산 속도에는 분명한 한계가 존재한다. 예를 들어, 일반적인 가정용 컴퓨터는 1초에 약 10억 회의 연산을 수행할 수 있다고 알려져 있다. 하지만 효율이 좋지 않은 알고리즘을 사용하거나, 처리해야 할 데이터가 지나치게 많을 경우, 전체 연산 횟수가 1경(10¹⁶)을 쉽게 넘어서게 된다. 이러한 상황에서는 우리가 작성한 프로그램이 실제로 동작하더라도, 결과를 얻기까지 몇 시간, 혹은 며칠이 걸릴 수 있으며, 이는 사실상 ‘쓸모없는 프로그램’이 되어버리는 것이다.

따라서 우리는 프로그램을 작성하기 전에 “이 프로그램은 얼마나 많은 연산을 수행하는가?”, “결과를 얻기까지 얼마나 걸릴 것인가?“를 예측할 수 있어야 하며, 그 판단의 핵심이 바로 **시간 복잡도(Time Complexity)** 개념이다.

## 시간 복잡도, Time Complexity

프로그래밍에서 **시간 복잡도(Time Complexity)**는 **입력값의 크기(n)**에 따라서 알고리즘이 수행하는 연산의 횟수를 나타낸 것을 내포한다. 다시 말해서, 입력된 값의 크기가 클 수록 프로그램이 얼마나 오랜 시간이 걸리는지를 나타내는 지표이다.

시간 복잡도는 코드가 실행되는 **시간**을 측정한 것이 아닌, **연산 횟수의 증가 추세**를 분석한 것이라고 봐야 한다. 따라서 컴퓨터의 성능이나 프로그래밍 언어의 차이 같은 경우는 외부적인 요소와 무관하게 알고리즘 자체의 성능을 판단할 수 있게 된다.

시간 복잡도를 표기하는데 있어 주로 `Big-O` 표기법을 이용한다. (해당 부분은 나중에 다룰 예정)

이러한 개념을 바탕으로 시간 복잡도를 이용하면 다음과 같은 상황에서 이점을 챙길 수 있다.
* 시간 복잡도는 입력 크기에 따른 상대적인 성능 비교
* 대략적인 실행 시간을 예측하여 실행 전에 해결 가능 여부 판단
* 알고리즘의 효율성을 판단

이러한 시간 복잡도가 가져다 주는 이점들을 이용하여 내가 작성한 코드들이 반환해주는 과정에서 효율적인 알고리즘을 선택 하였는지를 판단할 수 있게 되며, 문제의 출제 의도나 개발의 의도에 적합한 코드를 작성할 수 있게 된다는 중요한 포인트가 된다.

## 시간 복잡도 표기
**`Big-O` 표기법**을 알아보기 전에 간단한 내용을 짚고 넘어가겠다.    

> 1 부터 2N까지의 정수를 모두 더한 값을 구할 때 연산 횟수는?

$$2N - 1$$

이처럼 간단한 문제의 경우, 정확한 연산 횟수를 직접 구하는 것이 가능하다. 하지만 현실의 프로그래밍 문제들은 이보다 훨씬 더 복잡한 경우가 많고, 연산 과정도 다양하기 때문에 정확한 횟수를 일일이 세는 것은 상당히 어렵고 비효율적이다.

또한, 실제로는 2N회와 3N회의 차이는 큰 의미가 없다. 대부분의 경우, 입력의 크기에 따라 얼마나 빠르게 연산 횟수가 증가하는가가 더 중요합니다.

그래서 우리는 “대략 N번 정도의 연산이 필요하다”처럼, 연산 횟수의 성장 추세를 기준으로 복잡도를 예측해야 한다. 이럴 때 사용하는 것이 바로 **`Big-O` 표기법**입니다.

### 란다우 표기법
**란다우 표기법(Landau Notation)** 표기법은 알고리즘의 효율성을 표현할 때 사용되는 수학적인 표현 방법이다. 입력 크기 n이 커질수록 연산 횟수가 어떻게 증가하는지를 표현해준다.    
해당 표기법은 일반적으로 연산 홧수를 최악의 경우 (Worst-case)기준으로 나타내며, 다양한 상황에 따라 아래와 같은 표기법을 사용한다.

|표기법|의미|
|---|---|
|$$O(g(n))$$|최악의 경우 (Upper Bound)|
|$$\Omega(g(n))$$|최선의 경우 (Lower Bound)|
|$$\Theta(g(n))$$|평균 또는 정확한 경계 (Tight Bound)|

* $O(g(n))$    
가장 흔히 사용되는 $O$(Big O)는 알고리즘이 최악의 경우에 얼마나 많은 연산을 수행할지를 나타낸다.     
쉽게 말해 절대로 이 이상으로 걸리지 않는다는 보장을 한다.

* $\Omega(g(n))$    
알고리즘이 최선의 경우 최소한 이 정도의 연산을 해야 한다는 의미    
쉽게 말해 최소 시간의 경계선으로 생각하면 된다.

* $\Theta(g(n))$      
알고리즘이 항상 이 정도 수준의 연산을 수행한다는 의미     
최악과 최선이 동일한 수준일 떄 사용되는 표기법

### $Big - O$ 표기법?
란다우 표기법 중에서 흔히 사용되는 $Big - O$ 표기법은 알고리즘의 성능을 분석할 때, 입력값의 크기 n에 따라서 최악의 경우 얼마나 많은 연산이 되는지 나타낸다.     

이는 주로 다음과 같은 경우에 사용이 된다.
* 입력 데이터가 매우 많아졌을 때, 해당 알고리즘을 사용할 수 있는가?
* 가장 비효율적인 상황에서 실행 시간이 어느정도 소요되는가?    

> 그럼 최악의 경우를 기준으로 정하는 이유가 무엇일까?

그 이유는 최악의 경우를 기준으로 하면 알고리즘의 성능이 확실하게 보장할 수 있다는 점과 일반적으로 문제 해결 시 가장 오래 걸리는 상황에서도 견딜 수 있는 알고리즘을 선택하는 것이 중요하기 때문이다.

예를 들어 아래와 같은 코드가 있다고 가정하자.

```java
public class LinearSearch {
    public static boolean findTarget(int[] arr, int target) {
        for (int num : arr) {
            if (num == target) return true;
        }
        return false;
    }
}
```

만약에 해당 알고리즘의 최선의 경우와 최악의 경우 어떤 시간 복잡도를 갖는지 확인하자.    
* 최선의 경우 : 배열의 첫 요소가 target일 경우 -> $O(1)$
* 최악의 경우 : 끝까지 못 찾을 경우 -> $O(n)$    

물론 최선의 경우로 해결이 되어야 좋겠지만 실제 프로그램은 예상하지 못한 상황으로 성능이 저하될 수 있기 때문에 **항상 가장 오래 걸릴 수 있는 상황을 기준으로 성능을 예측** 하는 것이다.

따라서 예제 코드의 시간 복잡도는 $O(n)$가 된다.

### $Big - O$ 표기 과정       
간단하게 3개의 수식을 예로 들어서 어떻게 표기하는지 알아볼 차례이다.    
시간 복잡도료 표현하기 위해서는 연산 결과에 집중하는 것이 아닌 연산 횟수를 중점으로 봐야한다.

* $T_A(N)=2N^2+5N+10$    
$T_A(N)$에서 중요하게 봐야할 부분은 $2N^2$이다. 그렇기 때문에 나머지 부분은 과감하게 버린다. 그리고 $2N^2$과 $N^2$를 비교 했을 때 2를 곱한다고 해도 큰 차이는 없을 것이다.
$$\xcancel{2}N^2+\xcancel{5N}+\xcancel{10}$$ 
$$\therefore O(N^2)$$

* $T_B(N)=2log_2N+1$  
$$\xcancel{2}log_2N+\xcancel{1}$$
$$\therefore O(logN)$$

* $T_C(N)=2^N+5N^3+5N^2+9$
$$2^N+\xcancel{5N^3}+\xcancel{5N^2}+\xcancel{9}$$
$$\therefore O(2^N)$$

## 실제 적용
* [문제 1](https://github.com/jae9380/Pilot/blob/main/test/src/main/java/com/step2/RoadToBiodome01.java)

```java
    for (String num : args) {...} // n회
    for (Integer i : list) { counts[i]++; } // n회
    for (int i = 0; i < counts.length ; i++) { ... } // 1001회
```

$$\therefore O(N)$$

* [문제 2](https://github.com/jae9380/Pilot/blob/main/test/src/main/java/com/step2/RoadToBiodome02.java)

```java
    isItPalindrome(input);        // O(n)
    for (char c : input) push();  // O(n)
    for (int i = 0; i < n; i++) pop(); // O(n)
```
$$\therefore O(N)$$

## 병목 현상 분석 및 최적화   

프로그램을 실행시킬 때 특정 부분에서 실행 시간이 늘어나면서 전체 실행 시간에 영향을 주는 현상을 **병목 현상**이라고 칭한다.

이러한 현상은 주로 시간 복잡도가 좋지 않은 경우에 주로 발생할 수 있다는 것이다. 

예를 들어서 이러한 상황들이다.    
1. 입력 크기에 따라 기하급수적으로 증가하는 연산
    ```java
    void func(int depth) {
        if (depth == N) return;
        for (int i = 0; i < N; i++) {
            backtrack(depth + 1);  // O(N^N)
        }
    }
    ```
2. 중첩 반복문 연산
    ```java
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            // O(N^2) 연산
        }
    }
    ```    

두 상황의 공통점으로는 N의 값의 크기에 따라서 연산 홧수가 N배 또는 N의 제곱으로 늘어나게 된다는 점이다. 

> 그럼 N의 크기에 따라 연산 횟수가 증가하는 부분이 병목 현상의 원인일까?

위 상황 말고도 다른 상황에서도 병목 현상이 발생할 수 있다.

3. 불필요한 반복 연산 / 중복 계산
4. 입력 크기에 따라 기하급수적으로 증가하는 연산

이러한 상황 또한 병목 현상의 원인이 될 수 있다는 점을 알고 있어야 한다.


## Bonus 
// 문제01과 문제02의 시간 복잡도를 최적화 하기 위한 방법을 코드에 적용하고, 이전 코드와 시간 복잡도 차이를 Big O로 비교해본다.